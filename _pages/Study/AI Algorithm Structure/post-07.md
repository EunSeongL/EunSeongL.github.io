---
title: "Day6: Convolutional Neural Network"
tags:
    - CNN Model
    - CNN Arichitecture
date: "2025-06-30"
thumbnail: "/assets/img/AI/cnn.jpg"
---

## 이미지 분류
---
### **이미지 분류(Image Classification)**란 컴퓨터 비전 분야에서 이미지를 사전에 정의된 여러 클래스(범주) 중 하나 또는 여러 개로 분류하는 작업이다.<br>
### 분류 유형
    - 이진 분류(Binary): 두 개의 클래스(예: 정상/비정상) 중 하나로 분류.
    - 다중 클래스(Multiclass): 세 개 이상의 클래스 중 하나로 분류(예: 고양이/개/토끼).
    - 다중 라벨(Multilabel): 한 이미지가 여러 라벨을 동시에 가질 수 있음(예: 한 사진에 여러 색상 태그).
    - 계층적 분류(Hierarchical): 클래스가 계층 구조로 조직되어 상위-하위 개념을 구분함
### 이미지 분류의 핵심 단계
    - 데이터 수집: 충분한 양의 이미지와 라벨 확보.
    - 특징 추출: 이미지에서 의미 있는 특징(엣지, 색상, 질감 등) 추출.
    - 분류: 추출된 특징을 바탕으로 이미지를 올바른 클래스에 할당
---

## CNN 구성요소
---
### **CNN(Convolutional Neural Network, 합성곱 신경망)**은 이미지 분류에 매우 효과적인 딥러닝 모델

| 구성요소                          | 역할 및 설명                                                                                                 |
|-----------------------------------|-------------------------------------------------------------------------------------------------------------|
| 입력층(Input Layer)               | 원본 이미지의 픽셀 데이터를 입력받음. 이미지의 크기(예: 224x224x3)가 입력 크기를 결정함                    |
| 합성곱층(Convolutional Layer)     | 여러 개의 필터(커널)를 이미지에 슬라이딩하며 지역적 특징(엣지, 패턴 등)을 추출. 각 필터는 특성 맵을 만듦      |
| 활성화 함수(Activation Function)  | 주로 ReLU 사용. 음수 값을 0으로 바꿔주고, 비선형성을 부여해 복잡한 패턴 학습 가능하게 함                   |
| 풀링층(Pooling Layer)             | 특성 맵의 공간적 크기를 줄여 계산량 감소 및 과적합 방지. Max pooling(최댓값 추출)이 대표적                  |
| 완전 연결층(Fully Connected Layer)| 추출된 특징을 1차원 벡터로 변환(flatten) 후, 모든 뉴런이 서로 연결되어 최종 분류를 진행                    |
| 출력층(Output Layer)              | 클래스별 확률값을 출력. 다중 클래스 분류에서는 Softmax 함수로 확률값을 정규화함                             |
| 드롭아웃(Dropout, 선택적)         | 일부 뉴런을 무작위로 비활성화해 과적합을 방지하는 정규화 기법                                               |

---

## 이미지 학습과정

### 데이터 준비 및 전처리
- **이미지 수집 및 라벨링:**  
  충분한 양의 이미지를 수집하고, 각 이미지에 라벨(정답)을 부여.
- **데이터 증강(Data Augmentation):**  
  회전, 뒤집기, 밝기 조정 등으로 데이터 다양성 확보 및 과적합 방지.
- **정규화 및 리사이즈:**  
  픽셀 값을 0~1 범위로 정규화하고, 모델 입력 크기에 맞게 리사이즈.

### 특징 추출 및 모델 학습
- **합성곱/풀링/활성화:**  
  CNN의 여러 층을 거치며 이미지로부터 점점 더 추상적인 특징을 자동으로 추출.
- **완전 연결층:**  
  추출된 특징을 바탕으로 최종적으로 클래스별 확률을 산출.

### 평가 및 검증
- **검증 데이터셋 활용:**  
  학습에 사용하지 않은 별도의 데이터로 모델 성능 평가.
- **성능 개선:**  
  필요시 하이퍼파라미터 조정, 데이터 증강, 레이어 추가 등으로 성능 개선.

### 테스트 및 배포
- **실제 환경에서 미지의 이미지를 분류하여 모델의 실전 성능을 검증.**

---

## CNN 아키텍처
---
### CNN 아키텍처는 여러 층이 계층적으로 쌓여 있는 구조

| 아키텍처     | 주요 특징 및 구조                                                                                                 |
|-------------|------------------------------------------------------------------------------------------------------------------|
| LeNet-5     | 1998년 제안, 2개의 합성곱+풀링층, 3개의 완전 연결층. 소형 이미지(28x28, MNIST 등) 분류에 적합.                     |
| AlexNet     | 2012년 ILSVRC 우승, 5개의 합성곱층+3개의 완전 연결층, ReLU 활성화 함수 도입, 대규모 이미지(224x224) 분류에 사용.    |
| VGG-16      | 13개의 합성곱층+3개의 완전 연결층, 모든 합성곱 커널 크기 3x3, 깊은 구조(16층), 일관된 구조로 널리 사용.             |
| ResNet      | 2015년 ILSVRC 우승, 50~152개 층의 초심층 구조, 잔차 연결(residual connection)로 학습 효율 극대화.                   |
| Inception   | 다양한 크기의 필터를 병렬로 적용하여 다양한 스케일의 특징 추출, 연산 효율성 개선.                                   |
| MobileNet   | 모바일/임베디드 환경에 최적화, 경량화된 구조, 실시간 분류 가능.                                                    |

---

### 공통 구조

입력 → [합성곱 → 활성화 → 풀링] × N → (필요시 드롭아웃) → 완전 연결층 → 출력(Softmax)

---

### 특징

- **특징 추출부(Feature Extractor):**  
  여러 합성곱/풀링층이 반복되어 이미지의 저수준(엣지)부터 고수준(객체)까지 특징을 추출.

- **분류부(Classifier):**  
  완전 연결층에서 추출된 특징을 바탕으로 클래스별 확률을 산출.

---

### 정리

- 이미지 분류는 이미지를 클래스별로 자동 분류하는 작업이며, CNN은 이를 위한 대표적 딥러닝 모델입니다.
- CNN은 입력층, 합성곱층, 활성화함수, 풀링층, 완전 연결층, 출력층 등으로 구성되며, 각 층이 계층적으로 쌓여 특징을 추출하고 분류를 수행합니다.
- 학습과정은 데이터 준비, 전처리, 모델 학습, 평가, 테스트 순으로 진행됩니다.
- 대표적인 CNN 아키텍처로는 LeNet, AlexNet, VGG, ResNet, Inception, MobileNet 등이 있으며, 각각의 구조와 특징이 다릅니다.


## 실습

---

